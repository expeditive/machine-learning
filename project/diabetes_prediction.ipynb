{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## üß† What is Support Vector Machine?\n",
        "\n",
        "**Support Vector Machine (SVM)** is a **supervised machine learning algorithm** used for **classification** and **regression** tasks. It is especially powerful for binary classification.\n",
        "\n",
        "---\n",
        "\n",
        "## üí° Intuition Behind SVM\n",
        "\n",
        "Imagine you're given two types of data points in a 2D space (say, red dots and blue stars). SVM finds the **best line (or hyperplane in higher dimensions)** that separates the two classes **with the maximum margin**.\n",
        "\n",
        "> The goal is to find the **decision boundary** that **maximizes the margin** between the two classes.\n",
        "\n",
        "---\n",
        "\n",
        "## ‚öôÔ∏è Key Concepts\n",
        "\n",
        "### 1. **Hyperplane**\n",
        "- A decision boundary that separates different classes.\n",
        "- In 2D, it's a line.  \n",
        "- In 3D, it's a plane.  \n",
        "- In higher dimensions, it's called a hyperplane.\n",
        "\n",
        "### 2. **Support Vectors**\n",
        "- The **closest data points to the hyperplane**.\n",
        "- These are **critical** because they define the margin.\n",
        "- If you remove a support vector, the position of the hyperplane can change.\n",
        "\n",
        "### 3. **Margin**\n",
        "- The distance between the hyperplane and the **nearest support vectors**.\n",
        "- SVM tries to **maximize this margin** to make the classifier more robust.\n",
        "\n",
        "---\n",
        "\n",
        "## ‚ú® Types of SVM\n",
        "\n",
        "### üîπ **Linear SVM**\n",
        "Used when data is **linearly separable** ‚Äî a straight line (or plane) can divide the classes.\n",
        "\n",
        "### üîπ **Non-linear SVM**\n",
        "Used when data is **not linearly separable**. We use a **kernel function** to transform the input space into a higher dimension where a linear separator **can** be found.\n",
        "\n",
        "---\n",
        "\n",
        "## üß™ Kernels in SVM\n",
        "\n",
        "Kernels allow SVM to handle **non-linear** classification by transforming data into higher dimensions.\n",
        "\n",
        "### Common Kernels:\n",
        "| Kernel | Description |\n",
        "|--------|-------------|\n",
        "| `linear` | Best when data is linearly separable |\n",
        "| `polynomial` | Maps to a polynomial feature space |\n",
        "| `rbf` (Gaussian) | Great for complex boundaries |\n",
        "| `sigmoid` | Similar to neural networks |\n",
        "\n",
        "---\n",
        "\n",
        "## üîß Important Parameters in SVM\n",
        "\n",
        "| Parameter | Description |\n",
        "|----------|-------------|\n",
        "| `C` | Regularization parameter. Small `C` = smoother boundary, Large `C` = fewer misclassifications |\n",
        "| `kernel` | Kernel type: `'linear'`, `'rbf'`, `'poly'`, `'sigmoid'` |\n",
        "| `gamma` | Defines influence of a single training example. High gamma = close reach; low gamma = far reach |\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ Advantages\n",
        "\n",
        "- Works well in high-dimensional spaces.\n",
        "- Effective when the number of dimensions > number of samples.\n",
        "- Versatile with different kernel functions.\n",
        "\n",
        "---\n",
        "\n",
        "## ‚ùå Disadvantages\n",
        "\n",
        "- Not suitable for large datasets (training can be slow).\n",
        "- Performance drops when there's too much noise or overlapping classes.\n",
        "- Requires good tuning of hyperparameters.\n",
        "\n",
        "---\n",
        "\n",
        "## üìä Example Use Cases\n",
        "\n",
        "- Email spam detection\n",
        "- Face detection\n",
        "- Cancer classification (e.g., Diabetes prediction)\n",
        "- Handwriting recognition\n",
        "\n",
        "---\n",
        "\n",
        "Want a visual explanation or animation of how SVM separates classes using margins and kernels?"
      ],
      "metadata": {
        "id": "vMIiMtviSkoA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "oFt4enLIS2Dh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DATA COLLECTION AND ANALYSIS"
      ],
      "metadata": {
        "id": "NVcmn3LHUCN8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#loading the diabetes dataset to pandas dataframe\n",
        "diabetes_datset = pd.read_csv('/content/diabetes.csv')"
      ],
      "metadata": {
        "id": "CT1WVB-TT1Rx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iEV6d1kAbZeX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}